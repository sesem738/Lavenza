{'gpu_id': '2', 'cwd': None, 'if_cwd_time': True, 'expconfig': 'TSGTrXL', 'random_seed': 49, 'env': {'id': 'LunarLanderContinuous-v2', 'state_dim': 37, 'action_dim': 9, 'if_discrete_action': False, 'reward_dim': 1, 'target_reward': 2000000.0, 'max_step': 200}, 'agent': {'if_load_model': False, 'actor_path': '', 'critic_path': '', 'class_name': <class 'agent.AgentPPO'>, 'net_dim': 128, 'ratio_clip': 0.3, 'lambda_entropy': 0.05, 'lambda_gae_adv': 0.97, 'if_use_gae': True, 'if_use_dn': False, 'learning_rate': 0.0001, 'soft_update_tau': 0.00390625, 'gamma_att': 0.85, 'agent_name': 'AgentPPO'}, 'trainer': {'batch_size': 1024, 'policy_reuse': 4, 'sample_step': 3200}, 'interactor': {'horizon_step': 3200, 'reward_scale': 1, 'gamma': 0.99, 'rollout_num': 16}, 'buffer': {'max_buf': 3200, 'if_on_policy': True, 'if_per': False}, 'evaluator': {'pre_eval_times': 2, 'eval_times': 4, 'if_save_model': True, 'break_step': 100000, 'satisfy_reward_stop': False}, 'InitDict': {'state_dim': 37, 'mid_dim': 128, 'embeddingT': 32, 'embeddingS': 32, 'atthead': 4, 'attlayer': 1, 'action_dim': 9, 'block_size': 9, 'block_size_state': 1, 'batch_size': 1024, 'use_TS': False, 'use_GTrXL': True, 'use_attbias': False, 'init_gru_gate_bias': 2.0}}